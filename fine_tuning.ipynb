{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7c79e2de-8b79-4f06-825a-efb6e0a71d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=os.environ.get(\"OPENAI_API_KEY\"),\n",
    ")\n",
    "\n",
    "response = client.files.create(\n",
    "  file=open(\"articles_trimmed_new_1.jsonl\", \"rb\"),\n",
    "  purpose=\"fine-tune\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9af2c0aa-dcc6-4139-a6b8-6ce4b8b00d28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"FileObject(id='file-sUjBkhraDYSKK4VzIdGMevTo', bytes=3302, created_at=1729191039, filename='toy_chat_fine_tuning.jsonl', object='file', purpose='fine-tune', status='processed', status_details=None)\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''FileObject(id='file-sUjBkhraDYSKK4VzIdGMevTo', bytes=3302, created_at=1729191039, filename='toy_chat_fine_tuning.jsonl', object='file', purpose='fine-tune', status='processed', status_details=None)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3611eaad-1eaf-435a-9561-a8f7ca92c52c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FileObject(id='file-5Idid2RIzncv3kjEBOljfhVa', bytes=275992760, created_at=1729217629, filename='articles_trimmed_new_1.jsonl', object='file', purpose='fine-tune', status='processed', status_details=None)\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "88e41e62-6edc-4bec-9b19-be1c4c79c21f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num examples: 50000\n",
      "First example:\n",
      "{'role': 'system', 'content': 'Provide 1-2 line titles for articles'}\n",
      "{'role': 'user', 'content': 'AGILE DEVELOPMENT\\n\\nTeleconferencing Is the Pair Programming of the Future\\n\\nCollaboration for developers has never been easier.\\n\\nCoding via teleconference is similar to the situation above, but nobody has to shower!\\n\\nMy challenge to you…\\n\\nIf you’re a leading member of a development team that typically works separately, I triple-dog-dare you to:\\n\\nPick a task that you think will take two weeks for your development team to complete (working separately). Perhaps an upcoming backlog item. Invite your entire team to a call on MS Teams, Zoom, or whichever teleconferencing tool you use. Have them drop as many meetings as possible so that they’re free for all or most of the day. Start sharing your screen, talk about what you’re trying to do, and start coding while the rest of the team is watching. Start asking a few questions. Don’t force any structure on the process. Don’t stop coding. Work the entire day this way. (note: you may want to have the fastest typer do the screen-sharing/coding) Repeat the process for at least another 2–3 days that same week. ??? Profit.\\n\\nWhy?\\n\\nWell, screen-sharing over a teleconference is essentially pair programming without having to crowd around a single computer. There’s a number of additional advantages as well:\\n\\nYour team can work from anywhere in the world. This is particularly important now, of all times, due to the COVID-19 pandemic.\\n\\nInstead of being limited to a “pair”, you can have N developers (or even non-developers) contributing on the call.\\n\\nAnyone on the call who isn’t coding/screen-sharing can help by googling any issues that arise or pulling up documentation. They could also use their own machine to work on a related task while staying on the call.\\n\\nA long session with voice and video promotes team engagement and eliminates delays in communication.\\n\\nDevelopers can mute, take a break, etc. without disrupting the rest of the team.\\n\\nDevelopers can swap between which screen is being shared.\\n\\nModern teleconferencing tools like MS Teams let developers take control of each others’ computers.\\n\\nDevelopers have connected the world together in real-time. It’s time to use those same tools to accomplish great things together from anywhere in the world.\\n\\nMy personal experience\\n\\nWhether I realized it or not, I’ve been doing this for about 2 years now. I have a small team, and we screen-share via teleconference almost every single work day at some point. Often times we screen-share for most of the day. It’s not a special event to work this way; it’s just how we collaborate. I can’t believe what we’ve been able to figure out as a small, cohesive group vs. what each of us would’ve been able to figure out individually in the same timeframe. I’ve used this same practice a few times with people outside of the team to great success as well.\\n\\nThe combined knowledge of a development team is immense, and (in my opinion) it’s a shame if that knowledge is fragmented rather than working towards the same goal.\\n\\nSomething that one developer forgets might be something that another developer remembers. There’s minimal lag between a question being asked and the question being answered. After the call finishes, every developer knows exactly what happened and what work is remaining on the task or project.\\n\\nTry it out and see for yourself.'}\n",
      "{'role': 'assistant', 'content': 'Teleconferencing Is the Pair Programming of the Future'}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import tiktoken # for token counting\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "\n",
    "data_path = \"articles_trimmed_new_1.jsonl\"\n",
    "\n",
    "# Load the dataset\n",
    "with open(data_path, 'r', encoding='utf-8') as f:\n",
    "    dataset = [json.loads(line) for line in f]\n",
    "\n",
    "# Initial dataset stats\n",
    "print(\"Num examples:\", len(dataset))\n",
    "print(\"First example:\")\n",
    "for message in dataset[0][\"messages\"]:\n",
    "    print(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ee531eb2-cfa8-4e0a-9b56-b062efdec29a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No errors found\n"
     ]
    }
   ],
   "source": [
    "# Format error checks\n",
    "format_errors = defaultdict(int)\n",
    "\n",
    "for ex in dataset:\n",
    "    if not isinstance(ex, dict):\n",
    "        format_errors[\"data_type\"] += 1\n",
    "        continue\n",
    "        \n",
    "    messages = ex.get(\"messages\", None)\n",
    "    if not messages:\n",
    "        format_errors[\"missing_messages_list\"] += 1\n",
    "        continue\n",
    "        \n",
    "    for message in messages:\n",
    "        if \"role\" not in message or \"content\" not in message:\n",
    "            format_errors[\"message_missing_key\"] += 1\n",
    "        \n",
    "        if any(k not in (\"role\", \"content\", \"name\", \"function_call\", \"weight\") for k in message):\n",
    "            format_errors[\"message_unrecognized_key\"] += 1\n",
    "        \n",
    "        if message.get(\"role\", None) not in (\"system\", \"user\", \"assistant\", \"function\"):\n",
    "            format_errors[\"unrecognized_role\"] += 1\n",
    "            \n",
    "        content = message.get(\"content\", None)\n",
    "        function_call = message.get(\"function_call\", None)\n",
    "        \n",
    "        if (not content and not function_call) or not isinstance(content, str):\n",
    "            format_errors[\"missing_content\"] += 1\n",
    "    \n",
    "    if not any(message.get(\"role\", None) == \"assistant\" for message in messages):\n",
    "        format_errors[\"example_missing_assistant_message\"] += 1\n",
    "\n",
    "if format_errors:\n",
    "    print(\"Found errors:\")\n",
    "    for k, v in format_errors.items():\n",
    "        print(f\"{k}: {v}\")\n",
    "else:\n",
    "    print(\"No errors found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9d1641d9-5648-4af3-9811-f015806d354e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=os.environ.get(\"OPENAI_API_KEY\"),\n",
    ")\n",
    "\n",
    "job = client.fine_tuning.jobs.create(\n",
    "  training_file=\"file-5Idid2RIzncv3kjEBOljfhVa\",\n",
    "  model=\"gpt-4o-mini-2024-07-18\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cf619892-3d92-48b7-85fc-1c05f0a90d26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FineTuningJob(id='ftjob-5a1NUef4yMKKN3z1xAg7ooYj', created_at=1729218486, error=Error(code=None, message=None, param=None), fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(n_epochs='auto', batch_size='auto', learning_rate_multiplier='auto'), model='gpt-4o-mini-2024-07-18', object='fine_tuning.job', organization_id='org-k2PeUErkTQUe1i20vWc6OlmA', result_files=[], seed=992869779, status='validating_files', trained_tokens=None, training_file='file-5Idid2RIzncv3kjEBOljfhVa', validation_file=None, estimated_finish=None, integrations=[], user_provided_suffix=None)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8ecec881-51a4-4db9-9f5d-13d8644d68ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FineTuningJob(id='ftjob-5a1NUef4yMKKN3z1xAg7ooYj', created_at=1729218486, error=Error(code='exceeded_quota', message='Creating this fine-tuning job would exceed your hard limit, please check your plan and billing details.                     Cost of job ftjob-5a1NUef4yMKKN3z1xAg7ooYj: USD 167.43. Quota remaining for org-k2PeUErkTQUe1i20vWc6OlmA: USD 116.38.', param=None), fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(n_epochs=1, batch_size=33, learning_rate_multiplier=1.8), model='gpt-4o-mini-2024-07-18', object='fine_tuning.job', organization_id='org-k2PeUErkTQUe1i20vWc6OlmA', result_files=[], seed=992869779, status='failed', trained_tokens=None, training_file='file-5Idid2RIzncv3kjEBOljfhVa', validation_file=None, estimated_finish=None, integrations=[], user_provided_suffix=None)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.fine_tuning.jobs.retrieve(\"ftjob-5a1NUef4yMKKN3z1xAg7ooYj\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4f540a44-2839-491c-bf43-8e7efd57c649",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"FineTuningJob(id='ftjob-74ft7Aat5zCLN2A6oEKAnA38', created_at=1729195628, error=Error(code=None, message=None, param=None), fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(n_epochs=3, batch_size=2, learning_rate_multiplier=1.8), model='gpt-4o-mini-2024-07-18', object='fine_tuning.job', organization_id='org-k2PeUErkTQUe1i20vWc6OlmA', result_files=[], seed=1183855914, status='running', trained_tokens=None, training_file='file-lqAKQ1g061cWZKrUoE7FArmW', validation_file=None, estimated_finish=1729197559, integrations=[], user_provided_suffix=None)\""
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''FineTuningJob(id='ftjob-74ft7Aat5zCLN2A6oEKAnA38', created_at=1729195628, error=Error(code=None, message=None, param=None), fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(n_epochs=3, batch_size=2, learning_rate_multiplier=1.8), model='gpt-4o-mini-2024-07-18', object='fine_tuning.job', organization_id='org-k2PeUErkTQUe1i20vWc6OlmA', result_files=[], seed=1183855914, status='running', trained_tokens=None, training_file='file-lqAKQ1g061cWZKrUoE7FArmW', validation_file=None, estimated_finish=1729197559, integrations=[], user_provided_suffix=None)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f65e624c-8c28-4c40-ac63-746cc1a7e341",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"FineTuningJob(id='ftjob-74ft7Aat5zCLN2A6oEKAnA38', created_at=1729195628, error=Error(code=None, message=None, param=None), fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(n_epochs=3, batch_size=2, learning_rate_multiplier=1.8), model='gpt-4o-mini-2024-07-18', object='fine_tuning.job', organization_id='org-k2PeUErkTQUe1i20vWc6OlmA', result_files=[], seed=1183855914, status='running', trained_tokens=None, training_file='file-lqAKQ1g061cWZKrUoE7FArmW', validation_file=None, estimated_finish=1729197661, integrations=[], user_provided_suffix=None)\""
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''FineTuningJob(id='ftjob-74ft7Aat5zCLN2A6oEKAnA38', created_at=1729195628, error=Error(code=None, message=None, param=None), fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(n_epochs=3, batch_size=2, learning_rate_multiplier=1.8), model='gpt-4o-mini-2024-07-18', object='fine_tuning.job', organization_id='org-k2PeUErkTQUe1i20vWc6OlmA', result_files=[], seed=1183855914, status='running', trained_tokens=None, training_file='file-lqAKQ1g061cWZKrUoE7FArmW', validation_file=None, estimated_finish=1729197661, integrations=[], user_provided_suffix=None)'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
